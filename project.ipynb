{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkuQG_ob1F9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "0809c65e-8658-4328-d152-24303b77719f"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/data\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import spacy \n",
        "import re\n",
        "from sklearn.model_selection import train_test_split as splitter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "from gensim.models.callbacks import PerplexityMetric\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Embedding, LSTM ,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Activation, RepeatVector,Flatten, TimeDistributed, Input,Bidirectional,LocallyConnected1D,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/data\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb6aHRUFGbdW"
      },
      "source": [
        "#loading lyrics\n",
        "lyrics = pd.read_csv('data.csv')\n",
        "lyrics_data=list(lyrics['lyrics'].str.lower())\n",
        "artist_data=list(lyrics['artist'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b004gcwrJOIq"
      },
      "source": [
        "#pre processing\n",
        "def preprocessing(data):\n",
        "  processed_data=[]\n",
        "\n",
        "  #removing everything except numbers and words\n",
        "  for i in data:\n",
        "    x = re.sub(r'[^a-z]+',' ',i)\n",
        "    processed_data.append(x)\n",
        "\n",
        "  #tokenizing sentences\n",
        "  tokenized = [list(word_tokenize(i))[:100] for i in processed_data]\n",
        "\n",
        "  \n",
        "  '''\n",
        "  #removing stopword\n",
        "  stop_words= list(set(stopwords.words('english')))\n",
        "  middle=[]\n",
        "  for ind,i in enumerate(tokenized):\n",
        "    for index,j in enumerate(i):\n",
        "      if j not in stop_words:\n",
        "        middle.append(j)\n",
        "    tokenized[ind]=middle\n",
        "    middle=[]\n",
        "    '''\n",
        "  '''\n",
        "  #removing words with len < 2\n",
        "  middle=[]\n",
        "  for ind,i in enumerate(tokenized):\n",
        "    for index,j in enumerate(i):\n",
        "      if len(j) > 2:\n",
        "        middle.append(j)\n",
        "    tokenized[ind]=middle\n",
        "    middle=[] \n",
        "  \n",
        "  #lemmatizing\n",
        "  lemmatizer = WordNetLemmatizer() \n",
        "  middle=[]\n",
        "  for ind,i in enumerate(tokenized):\n",
        "    for index,j in enumerate(i):\n",
        "      middle.append(lemmatizer.lemmatize(j))\n",
        "  tokenized[ind]=middle\n",
        "  middle=[]\n",
        "  '''\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  return tokenized\n",
        "\n",
        "  \n",
        "processed_data=preprocessing(lyrics_data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-ogEKFUx65"
      },
      "source": [
        "#splitting data in test,valid,train 20 10 70\n",
        "def split(data,labels):\n",
        "  train_data,valid_data,train_labels,valid_labels=splitter(data,labels,train_size=0.9,test_size=0.1,shuffle=True)\n",
        "  train_data,test_data,train_labels,test_labels=splitter(train_data,train_labels,train_size=0.8,test_size=0.2,shuffle=True)\n",
        "\n",
        "  return train_data,train_labels,test_data,test_labels,valid_data,valid_labels\n",
        "\n",
        "train_data,train_labels,test_data,test_labels,valid_data,valid_labels=split(processed_data,artist_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSZS3yZIW5qE"
      },
      "source": [
        "#one hot encoding labels\n",
        "#Eminem G-eazy Kendrick MGK\n",
        "def one_hot(labels):\n",
        "  label_encoder = LabelEncoder()\n",
        "  integer_encoded = label_encoder.fit_transform(labels)\n",
        "  onehot_encoder = OneHotEncoder(sparse=False)\n",
        "  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "  onehot_encoded= onehot_encoder.fit_transform(integer_encoded)\n",
        "  return np.array(onehot_encoded)\n",
        "\n",
        "encoded_train_labels = one_hot(train_labels)\n",
        "encoded_test_labels  = one_hot(test_labels)\n",
        "encoded_valid_labels = one_hot(valid_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzrUY2enQzql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a4c7969b-00ae-4368-9dbc-01d247aef8b7"
      },
      "source": [
        "#callbacks\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "  def __init__(self):\n",
        "    self.epoch = 0\n",
        "  def on_epoch_begin(self, model):\n",
        "    print(\"Epoch #{} start\".format(self.epoch))\n",
        "  def on_epoch_end(self, model):\n",
        "    print(\"Epoch #{} end\".format(self.epoch))\n",
        "    self.epoch += 1\n",
        "\n",
        "#word2vec\n",
        "epoch_logger = EpochLogger()\n",
        "perplexity_logger = PerplexityMetric(corpus=train_data, logger='shell')\n",
        "model = Word2Vec(train_data, size=200, window=3,iter=1000)\n",
        "model.save(\"word2vec.model\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej-pTnQJo1WN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfwUzvXFjqaY"
      },
      "source": [
        "#loading pretrained embeddings\n",
        "path = '/content/drive/My Drive/Colab Notebooks/data/glove.6B.100d.txt'\n",
        "with open(path,'r')as f:\n",
        "  lines=f.readlines()\n",
        "  f.close()\n",
        "emb={}\n",
        "for i in lines:\n",
        "  line=i.split(\" \")\n",
        "  word=line[0]\n",
        "  emb[word]=[float(j) for j in line[1:]]\n",
        "#adding 0\n",
        "emb['UNK']=np.zeros(100,dtype='float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsERBOPfHSY_"
      },
      "source": [
        "# __CNN__ implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD4hl32Oz9oZ"
      },
      "source": [
        "#get vocab size\n",
        "def getvocab(data):\n",
        "  raw_count = 0\n",
        "  vocab = []\n",
        "  for i in data:\n",
        "    for j in i:\n",
        "      raw_count +=1\n",
        "      if j not in vocab:\n",
        "        vocab.append(j)\n",
        "  return raw_count,vocab\n",
        "\n",
        "raw_count,vocab = getvocab(train_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CleQrz7R0Pts",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ea1c788-b445-4a9f-bb56-17213563c84f"
      },
      "source": [
        "raw_count\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qptnf3Fo-aoC"
      },
      "source": [
        "#pooling functions\n",
        "#Fast text averaging, pass a list of word embeddings and embedding size to fasttextAveraging function\n",
        "def l2_norm(x):\n",
        "   return np.sqrt(np.sum(x**2))\n",
        "\n",
        "def div_norm(x):\n",
        "   norm_value = l2_norm(x)\n",
        "   if norm_value > 0:\n",
        "       return x * ( 1.0 / norm_value)\n",
        "   else:\n",
        "       return x\n",
        "def fasttextAveraging(embedding_list,embedding_size):\n",
        "    norm=np.zeros(embedding_size)\n",
        "    for emb in embedding_list:\n",
        "        norm=norm+div_norm(emb) \n",
        "    return norm/len(embedding_list)\n",
        "\n",
        "def averagePooling(embedding_list,embedding_size):\n",
        "  return np.mean(embedding_list,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjRTCOWQ3w0Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ea7dacb5-2f37-46fe-faf2-f83ef6892090"
      },
      "source": [
        "#making embeddings\n",
        "def embed(model,data,size):\n",
        "  emb_size = size\n",
        "  middle=[]\n",
        "  matrix =np.zeros((len(data),emb_size))\n",
        "  for index,i in enumerate(data):\n",
        "    for j in i:\n",
        "      try:\n",
        "        middle.append(model.wv[j])\n",
        "      except:\n",
        "        continue\n",
        "    middle = averagePooling(middle,emb_size)\n",
        "    matrix[index]=middle\n",
        "    middle=[]\n",
        "  return matrix\n",
        "\n",
        "train_matrix = embed(emb,train_data,100)\n",
        "test_matrix  = embed(emb,test_data,100)\n",
        "vaid_matrix  = embed(emb,valid_data,100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzV2lZxc_NFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "2f4e4bdb-de6e-48c6-998d-fd4586af8aa1"
      },
      "source": [
        "#modelling\n",
        "#keras sequential api\n",
        "embedding_size=100\n",
        "\"\"\"model_word2vec = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(embedding_size,)),#donot change(input layer)\n",
        "    keras.layers.Dense(100, activation='relu'),#(hidden layer)\n",
        "    keras.layers.Dense(50, activation='relu'),#(hidden layer)\n",
        "    keras.layers.Dense(4)#donot change\n",
        "])\n",
        "adam=keras.optimizers.Adam(lr=0.00001)\n",
        "model_word2vec.compile(optimizer=adam,\n",
        "              loss=[\"categorical_crossentropy\"],\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_word2vec.summary()\"\"\"\n",
        "\n",
        "model1 = Sequential()\n",
        "\n",
        "model1.add(layers.Embedding(vocab_size+1, embedding_size, input_length=100))\n",
        "model1.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model1.add(layers.GlobalMaxPooling1D())\n",
        "model1.add(layers.Dense(10, activation='relu'))\n",
        "model1.add(layers.Dense(4, activation='sigmoid'))\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model1.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 100, 100)          382500    \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 447,962\n",
            "Trainable params: 447,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nloCHJDqBKQk"
      },
      "source": [
        "#callbacks\n",
        "filepath = \"setting_\" + \"model1\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model1\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, reduce_lr, checkpoint]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgaABD_GBPRg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "42022b39-32ac-4f15-f4c9-fc87e06a6f1a"
      },
      "source": [
        "#training\n",
        "model1.fit(train_matrix,encoded_train_labels, epochs=100, batch_size=25,verbose=1,shuffle=True,validation_data=(vaid_matrix,encoded_valid_labels),callbacks = callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-ae7a2b066430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaid_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_valid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[21,91] = -2147483648 is not in [0, 3825)\n\t [[node sequential_9/embedding_8/embedding_lookup (defined at <ipython-input-44-ae7a2b066430>:2) ]] [Op:__inference_train_function_17092]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_9/embedding_8/embedding_lookup:\n sequential_9/embedding_8/embedding_lookup/16811 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml8PADG3HgFK"
      },
      "source": [
        "# __RNN__ implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oojj1SkOId6U"
      },
      "source": [
        "#getting vocab \n",
        "def vocab(data):\n",
        "  tokenizer=Tokenizer(oov_token=\"UNK\")\n",
        "  tokenizer.fit_on_texts(data)\n",
        "  vocab = list(tokenizer.word_index.keys())\n",
        "  vocab_size = len(vocab)\n",
        "  return tokenizer,vocab,vocab_size\n",
        "tokenizer,vocab,vocab_size = vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0segpZUqiWZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24c67ead-e091-4020-ccc4-9dd6e92b588b"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2Gu2x9iI5Ks"
      },
      "source": [
        "#converting to sequences and adding post padding\n",
        "def text2seq(tokenizer,data):\n",
        "\n",
        "  seq=tokenizer.texts_to_sequences(data)\n",
        "  #padding\n",
        "  seq=pad_sequences(seq,padding=\"post\",maxlen=100)\n",
        "  return seq\n",
        "\n",
        "train_seq = text2seq(tokenizer,train_data)\n",
        "valid_seq = text2seq(tokenizer,valid_data)\n",
        "test_seq  = text2seq(tokenizer,test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWulupqzJqU4"
      },
      "source": [
        "#creating embeddings \n",
        "def embed(model,vocab,Emb_dim):\n",
        "  emb_matrix = np.zeros((len(vocab)+1,Emb_dim))\n",
        "  for index,i in enumerate(vocab):\n",
        "      try:\n",
        "          emb_matrix[index]=model[i]\n",
        "      except:\n",
        "        continue\n",
        "  return emb_matrix\n",
        "\n",
        "embeddings =embed(emb,vocab,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6owp-zxdMhuw"
      },
      "source": [
        "filepath = \"setting_\" + \"model1\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model1\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, reduce_lr, checkpoint,earlyStopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R85nzHxyKLmK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "1e8bf01d-e7bf-4e59-8aa0-4ba7808a9592"
      },
      "source": [
        "#initializing models\n",
        "Emb_dim = 100\n",
        "input_layer=Input(shape=(100,))\n",
        "emb=Embedding(vocab_size+1,Emb_dim,weights=[embeddings],input_length=100,trainable=True)\n",
        "emb_out = emb(input_layer)\n",
        "lstm=LSTM(25,return_state=True,return_sequences=True)\n",
        "lstm_out,_,_ = lstm(emb_out)\n",
        "drop1=Dropout(0.5)(lstm_out)\n",
        "lstm2 = LSTM(25,return_state=False,return_sequences=False,kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))\n",
        "lstm2_out=lstm2(drop1)\n",
        "drop2 = Dropout(0.5)(lstm2_out)\n",
        "output=Dense(4,activation='sigmoid')(drop2)\n",
        "\n",
        "model1 = Model(inputs=[input_layer], outputs=[output])\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
        "model1.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 100, 100)          382500    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 100, 25), (None,  12600     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 25)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 25)                5100      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 104       \n",
            "=================================================================\n",
            "Total params: 400,304\n",
            "Trainable params: 400,304\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_VRUc6gLfnZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "209147b4-042e-4666-e4b0-db6b0646e875"
      },
      "source": [
        "\n",
        "model1.fit(train_seq,encoded_train_labels, epochs=100,validation_data=(valid_seq,encoded_valid_labels),verbose=1,shuffle=True,callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.9694 - categorical_accuracy: 0.8333WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.9694 - categorical_accuracy: 0.8333 - val_loss: 2.1911 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.9134 - categorical_accuracy: 0.7986WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.9134 - categorical_accuracy: 0.7986 - val_loss: 2.1244 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8766 - categorical_accuracy: 0.8368WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.8766 - categorical_accuracy: 0.8368 - val_loss: 2.0700 - val_categorical_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8433 - categorical_accuracy: 0.8403WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.8433 - categorical_accuracy: 0.8403 - val_loss: 2.1026 - val_categorical_accuracy: 0.2750 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.8273 - categorical_accuracy: 0.7882WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.8273 - categorical_accuracy: 0.7882 - val_loss: 2.1130 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7815 - categorical_accuracy: 0.8472WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.7815 - categorical_accuracy: 0.8472 - val_loss: 2.1692 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7438 - categorical_accuracy: 0.8715WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.7438 - categorical_accuracy: 0.8715 - val_loss: 2.1796 - val_categorical_accuracy: 0.4250 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7040 - categorical_accuracy: 0.8785WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.7040 - categorical_accuracy: 0.8785 - val_loss: 2.2591 - val_categorical_accuracy: 0.3250 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6991 - categorical_accuracy: 0.8889WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.6991 - categorical_accuracy: 0.8889 - val_loss: 2.4004 - val_categorical_accuracy: 0.3750 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6782 - categorical_accuracy: 0.9167WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.6782 - categorical_accuracy: 0.9167 - val_loss: 2.3460 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6521 - categorical_accuracy: 0.9167WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.6521 - categorical_accuracy: 0.9167 - val_loss: 2.4344 - val_categorical_accuracy: 0.3250 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6039 - categorical_accuracy: 0.9514WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.6039 - categorical_accuracy: 0.9514 - val_loss: 2.8301 - val_categorical_accuracy: 0.2250 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5859 - categorical_accuracy: 0.9549WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5859 - categorical_accuracy: 0.9549 - val_loss: 2.3396 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5515 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5515 - categorical_accuracy: 0.9792 - val_loss: 2.3961 - val_categorical_accuracy: 0.3500 - lr: 2.0000e-04\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5438 - categorical_accuracy: 0.9688WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5438 - categorical_accuracy: 0.9688 - val_loss: 2.4053 - val_categorical_accuracy: 0.3500 - lr: 2.0000e-04\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5386 - categorical_accuracy: 0.9931WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.5386 - categorical_accuracy: 0.9931 - val_loss: 2.3844 - val_categorical_accuracy: 0.3500 - lr: 2.0000e-04\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5434 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5434 - categorical_accuracy: 0.9792 - val_loss: 2.4235 - val_categorical_accuracy: 0.3750 - lr: 2.0000e-04\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5214 - categorical_accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5214 - categorical_accuracy: 0.9826 - val_loss: 2.4439 - val_categorical_accuracy: 0.3750 - lr: 2.0000e-04\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5322 - categorical_accuracy: 0.9688WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.5322 - categorical_accuracy: 0.9688 - val_loss: 2.3801 - val_categorical_accuracy: 0.3750 - lr: 2.0000e-04\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5109 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.5109 - categorical_accuracy: 0.9896 - val_loss: 2.3639 - val_categorical_accuracy: 0.3750 - lr: 2.0000e-04\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5190 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.5190 - categorical_accuracy: 0.9861 - val_loss: 2.4926 - val_categorical_accuracy: 0.3000 - lr: 2.0000e-04\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4903 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.4903 - categorical_accuracy: 0.9861 - val_loss: 2.5521 - val_categorical_accuracy: 0.2750 - lr: 2.0000e-04\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5188 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5188 - categorical_accuracy: 0.9792 - val_loss: 2.4429 - val_categorical_accuracy: 0.3250 - lr: 2.0000e-04\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4849 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.4849 - categorical_accuracy: 0.9896 - val_loss: 2.4355 - val_categorical_accuracy: 0.3250 - lr: 4.0000e-05\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4824 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4824 - categorical_accuracy: 0.9896 - val_loss: 2.4416 - val_categorical_accuracy: 0.3250 - lr: 4.0000e-05\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5054 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5054 - categorical_accuracy: 0.9792 - val_loss: 2.4527 - val_categorical_accuracy: 0.3250 - lr: 4.0000e-05\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4986 - categorical_accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4986 - categorical_accuracy: 0.9826 - val_loss: 2.4975 - val_categorical_accuracy: 0.3000 - lr: 4.0000e-05\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4833 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4833 - categorical_accuracy: 0.9896 - val_loss: 2.5223 - val_categorical_accuracy: 0.3000 - lr: 4.0000e-05\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4768 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.4768 - categorical_accuracy: 0.9792 - val_loss: 2.5135 - val_categorical_accuracy: 0.3000 - lr: 4.0000e-05\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4788 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4788 - categorical_accuracy: 0.9861 - val_loss: 2.4930 - val_categorical_accuracy: 0.3250 - lr: 4.0000e-05\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4983 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.4983 - categorical_accuracy: 0.9861 - val_loss: 2.4723 - val_categorical_accuracy: 0.3250 - lr: 4.0000e-05\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4868 - categorical_accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.4868 - categorical_accuracy: 0.9826 - val_loss: 2.4867 - val_categorical_accuracy: 0.3250 - lr: 4.0000e-05\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4753 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4753 - categorical_accuracy: 0.9861 - val_loss: 2.5036 - val_categorical_accuracy: 0.3250 - lr: 4.0000e-05\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5033 - categorical_accuracy: 0.9653WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5033 - categorical_accuracy: 0.9653 - val_loss: 2.5064 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.5178 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.5178 - categorical_accuracy: 0.9792 - val_loss: 2.5022 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4767 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4767 - categorical_accuracy: 0.9792 - val_loss: 2.5060 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4875 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4875 - categorical_accuracy: 0.9861 - val_loss: 2.5064 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4782 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.4782 - categorical_accuracy: 0.9792 - val_loss: 2.5034 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4928 - categorical_accuracy: 0.9722WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.4928 - categorical_accuracy: 0.9722 - val_loss: 2.4947 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4865 - categorical_accuracy: 0.9757WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4865 - categorical_accuracy: 0.9757 - val_loss: 2.4918 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4799 - categorical_accuracy: 0.9931WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.4799 - categorical_accuracy: 0.9931 - val_loss: 2.4904 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4760 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4760 - categorical_accuracy: 0.9896 - val_loss: 2.4912 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4923 - categorical_accuracy: 0.9965WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4923 - categorical_accuracy: 0.9965 - val_loss: 2.4972 - val_categorical_accuracy: 0.3250 - lr: 8.0000e-06\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4890 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4890 - categorical_accuracy: 0.9861 - val_loss: 2.4979 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4967 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4967 - categorical_accuracy: 0.9861 - val_loss: 2.4989 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4687 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4687 - categorical_accuracy: 0.9861 - val_loss: 2.4973 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4875 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.4875 - categorical_accuracy: 0.9896 - val_loss: 2.4985 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4835 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4835 - categorical_accuracy: 0.9861 - val_loss: 2.5000 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4667 - categorical_accuracy: 0.9931WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4667 - categorical_accuracy: 0.9931 - val_loss: 2.5018 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4855 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.4855 - categorical_accuracy: 0.9861 - val_loss: 2.5015 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4749 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.4749 - categorical_accuracy: 0.9896 - val_loss: 2.5002 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4906 - categorical_accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4906 - categorical_accuracy: 0.9826 - val_loss: 2.4985 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4908 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.4908 - categorical_accuracy: 0.9792 - val_loss: 2.4968 - val_categorical_accuracy: 0.3250 - lr: 1.6000e-06\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4906 - categorical_accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4906 - categorical_accuracy: 0.9792 - val_loss: 2.4964 - val_categorical_accuracy: 0.3250 - lr: 3.2000e-07\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.9931WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.4714 - categorical_accuracy: 0.9931 - val_loss: 2.4962 - val_categorical_accuracy: 0.3250 - lr: 3.2000e-07\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4908 - categorical_accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.4908 - categorical_accuracy: 0.9826 - val_loss: 2.4955 - val_categorical_accuracy: 0.3250 - lr: 3.2000e-07\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4854 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4854 - categorical_accuracy: 0.9896 - val_loss: 2.4954 - val_categorical_accuracy: 0.3250 - lr: 3.2000e-07\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4840 - categorical_accuracy: 0.9896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.4840 - categorical_accuracy: 0.9896 - val_loss: 2.4960 - val_categorical_accuracy: 0.3250 - lr: 3.2000e-07\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.4873 - categorical_accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy,lr\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.4873 - categorical_accuracy: 0.9861 - val_loss: 2.4964 - val_categorical_accuracy: 0.3250 - lr: 3.2000e-07\n",
            "Epoch 60/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8a614e827c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_valid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}